[mixturemodel]
use_mixture_prior=true
λ_reg=0.0
use_attention_kernel=false
train_proportions=false

[prior_langevin]
step_size=0.16
iters=60

[optimizer]
betas=0.9,0.999
decay=0
ε=0.000000008
ρ=0.9
learning_rate=NaN
type=nesterov

[training]
gen_every=2
N_epochs=20
batch_size=50
verbose=true
update_grid=true
dataset=MNIST
eps=0.0001
N_train=20000
N_test=2000
checkpoint_every=-1
use_perceptual_loss=false
contrastive_divergence_training=true
num_generated_samples=3000
resampling_threshold_factor=0.5
use_gpu=true

[cnn]
activation =gelu
hidden_feature_dims=64,32,16
strides=1,2,2,2
latent_concat=false
kernel_sizes=4,4,4,4
activation=leakyrelu
batchnorm=false
paddings=0,1,1,1
use_cnn_lkhood=true

[tuning]
sampler=bcap
num_trials=200

[post_langevin]
step_size_bounds=0.00001,10
initial_step_size=NaN
use_langevin=true
iters=40

[ebmmodel]
grid_size=50
μ_scale=1
σ_spline=1
grid_update_ratio=0.05
spline_function=FFT
ε_scale=1
GaussQuad_nodes=200
quadrature_method=gausslegendre
grid_range=-1,1
τ_trainable=true
spline_degree=3
layer_widths=40,81
σ_base=1
base_activation=relu
π_0=ebm
layernorm=false
init_τ=1

[lr_schedule]
decay=NaN
milestone_epochs=5,10,15

[grid_updating]
update_prior_grid=true
grid_update_frequency=50
grid_update_decay=0.9999
update_llhood_grid=false

[seq]
d_model=128
sequence_length=0
activation=relu
vocab_size=1000

[pca]
use_pca=false
pca_components=800

[generatormodel]
resampler=residual
perceptual_scale=0.0001
grid_size=100
μ_scale=1
σ_spline=1
grid_update_ratio=0.05
spline_function=FFT
ε_scale=1
grid_range=-1.5,1.5
output_activation=sigmoid
τ_trainable=true
base_activation =relu
spline_degree=3
σ_base=1
widths=81,162
base_activation=relu
layernorm=false
init_τ=1
generator_variance=NaN
generator_noise=NaN

[thermodynamic_integration]
p_end=4
num_cycles=0
N_langevin_per_temp=40
num_temps=-1
p_start=0.8

